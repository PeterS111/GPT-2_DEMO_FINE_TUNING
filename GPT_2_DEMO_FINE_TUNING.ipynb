{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2_DEMO_FINE_TUNING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterS111/GPT-2_DEMO_FINE_TUNING/blob/main/GPT_2_DEMO_FINE_TUNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgyvXfsVrQ0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b572810-d083-4d21-c395-c244f5468e32"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec 11 09:45:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3Qv6nfmrXPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9086776c-816f-431f-f937-d87f84d09990"
      },
      "source": [
        "!git clone https://github.com/PeterS111/GPT-2_DEMO_FINE_TUNING  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GPT-2_DEMO_FINE_TUNING'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 18 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_xfH-FJrXne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd77adc-811f-441f-fb4a-565ab1567bd3"
      },
      "source": [
        "cd /content/GPT2_HEAD"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GPT2_HEAD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07S832Y0rX1y"
      },
      "source": [
        "pip install \"transformers==2.7.0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryAY2670rYEJ"
      },
      "source": [
        "## TRAIN WITHOUT VALIDATION\n",
        "!python run_lm_finetuning.py --output_dir=output  --model_type=gpt2 --model_name_or_path=gpt2 --do_train  --train_data_file=input_data/Shelley_4.txt --overwrite_output_dir --block_size=200 --per_gpu_train_batch_size=1 --save_steps 100 --save_total_limit 1000 --num_train_epochs=5 --logging_steps=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riej0YolrYVt"
      },
      "source": [
        "## TRAIN WITH VALIDATION\n",
        "!python run_lm_finetuning.py --output_dir=output  --model_type=gpt2 --model_name_or_path=gpt2 --do_train  --train_data_file=input_data/Shelley_4.txt --overwrite_output_dir --block_size=200 --per_gpu_train_batch_size=1 --save_steps 100 --save_total_limit 1000 --num_train_epochs=5000 --logging_steps=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfghN19WHxpv"
      },
      "source": [
        "To train from checkpoint:\r\n",
        "1. Create \"output\" folder inside the \"input data\"\r\n",
        "2. Get a copy of cached file of input data, eg.: \"gpt2_cached_lm_200_Shelley_4.txt\"\r\n",
        "3. Rename it to: \"checkpoint-300_cached_lm_200_Shelley_4.txt\" and put in \"input_data/output/\"\r\n",
        "4. Run TRAIN FROM CHECKPOINT WITHOUT VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5WUOI7brYil"
      },
      "source": [
        "## TRAIN FROM CHECKPOINT WITHOUT VALIDATION\n",
        "!python run_lm_finetuning.py --output_dir=output  --model_type=gpt2 --model_name_or_path=output/checkpoint-300 --do_train --train_data_file=input_data/Shelley_4.txt --overwrite_output_dir --block_size=200 --per_gpu_train_batch_size=1 --save_steps 100 --save_total_limit 1000 --num_train_epochs=5000 --logging_steps=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwZVfQJbIQCa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DgwL-WYy2kp"
      },
      "source": [
        "## TRAIN FROM CHECKPOINT WITH VALIDATION\n",
        "!python run_lm_finetuning.py --output_dir=output  --model_type=gpt2 --model_name_or_path=output/checkpoint-200 --do_train --eval_data_file=input_data/Shelley_4a_val.txt --do_eval --evaluate_during_training --train_data_file=input_data/Shelley_4a_train.txt --overwrite_output_dir --block_size=200 --per_gpu_train_batch_size=1 --save_steps 10000 --save_total_limit 1000 --num_train_epochs=5000 --logging_steps=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAbhLuferZKe"
      },
      "source": [
        "## TEST GENERATION\n",
        "!python run_serial_generation.py --model_type gpt2 --temperature 1.0 --top_k 50 --top_p 1.0 --model_name_or_path output/checkpoint-500 --length 500 --prompt \"The eternal sky \" --seed 37 --num_samples 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psapBGyyvCVs"
      },
      "source": [
        "## ZIPPING TRAINED MODEL FOR EXPORT\n",
        "!tar -czvf \"S4_SHM_300.tar.gz\" output/checkpoint-300/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3HS2_qivCo7"
      },
      "source": [
        "## REMOVE FILES\n",
        "!rm -vR /content/GPT2_HEAD/output/checkpoint-300/  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjG5YkiNx1jx"
      },
      "source": [
        "## MOUNTING GOOGLE DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P3s6ZgNvC3S"
      },
      "source": [
        "## EXPORTING FILE TO DRIVE\n",
        "!cp \"S4_SHM_300.tar.gz\" \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9xw7VNmvDGH"
      },
      "source": [
        "## IMPORTING FILE FROM DRIVE\n",
        "## 1. CREATE OUTPUT FOLDER IF DOESN'T EXIST:\n",
        "!mkdir output/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrF-v_SZ232k"
      },
      "source": [
        "## 2. IMPORT THE MODEL:\n",
        "!cp \"/content/drive/My Drive/S4_SHM_300.tar.gz\" /content/GPT2_HEAD/output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xyKdKbzvDUT"
      },
      "source": [
        "## UNZIPPING IMPORTED MODEL AND REMOVING ZIPPED FILE\n",
        "!tar xf /content/GPT2_HEAD/output/S4_SHM_300.tar.gz\n",
        "!rm -v /content/GPT2_HEAD/output/S4_SHM_300.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBgJnJB5vDj_"
      },
      "source": [
        "## GENERATION:\n",
        "# edit: \"run_serial_g.py\"\n",
        "!python run_serial_g.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br5Ujakv6-hZ"
      },
      "source": [
        "cd GPT2_HEAD/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGc5PRC47EmI"
      },
      "source": [
        " !python run_generation.py --model_type gpt2 --temperature 1.0 --top_k 50 --top_p 1.0 --model_name_or_path \"/content/GPT2_HEAD/output/checkpoint-300\" --length 700 --prompt \"The eternal sky \" --seed 56 --num_samples 1 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2yz3Bse7xoi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}